{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T09:46:22.268355Z","iopub.status.busy":"2022-04-26T09:46:22.267515Z","iopub.status.idle":"2022-04-26T09:46:22.277011Z","shell.execute_reply":"2022-04-26T09:46:22.276060Z","shell.execute_reply.started":"2022-04-26T09:46:22.268190Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.feature_selection import chi2\n","from sklearn.feature_selection import f_classif\n","from sklearn import metrics\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import category_encoders as ce\n","import json\n","from textblob import TextBlob\n","from scipy import stats\n","from sklearn import preprocessing\n","from geopy import distance\n","import time\n"]},{"cell_type":"markdown","metadata":{},"source":["# Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T09:46:26.256859Z","iopub.status.busy":"2022-04-26T09:46:26.256137Z","iopub.status.idle":"2022-04-26T09:46:26.262189Z","shell.execute_reply":"2022-04-26T09:46:26.261210Z","shell.execute_reply.started":"2022-04-26T09:46:26.256813Z"},"trusted":true},"outputs":[],"source":["DEBUG = True\n","INDEX_COLUMN_NAME = None\n","RANDOM_STATE = 12\n","SOURCE_DIR = './'\n","# SOURCE_DIR = '../input/sf-booking/'\n","TARGET_COLUMN_NAME = 'reviewer_score'\n","TEST_SIZE = 0.25"]},{"cell_type":"markdown","metadata":{},"source":["# Helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T09:46:22.279731Z","iopub.status.busy":"2022-04-26T09:46:22.279197Z","iopub.status.idle":"2022-04-26T09:46:22.307241Z","shell.execute_reply":"2022-04-26T09:46:22.305579Z","shell.execute_reply.started":"2022-04-26T09:46:22.279664Z"},"trusted":true},"outputs":[],"source":["def figax(figsize=(7, 4), rowcol=None, axes=[0,0,1,1], name='Foo'):\n","    fig = plt.figure(name, figsize=figsize)\n","    \n","    if rowcol is None:\n","        ax = fig.add_axes(axes)\n","    else:\n","        rows, cols = rowcol\n","        ax = fig.subplots(rows, cols)\n","\n","    return fig, ax\n","\n","def describe_hist_box(data, column, log=False):\n","    global DEBUG\n","\n","    if not DEBUG:\n","        return\n","\n","    data=hotels[[column]]\n","\n","    # print(data.describe())\n","\n","    fig, ax = figax(rowcol=(2, 1), name=column)\n","\n","    sns.histplot(ax=ax[0], data=data, binwidth=1)\n","    sns.boxplot(ax=ax[1], data=data, orient='h')\n","\n","    if log:\n","        ax[0].set_xscale('log')\n","        ax[1].set_xscale('log')\n","\n","def convert_rare_values_to_others(data=None, feature='', how_many_to_keep=15):\n","    value_counts = data[feature].value_counts()\n","\n","    difference_times = value_counts[0] / value_counts[how_many_to_keep]\n","\n","    if difference_times < 100:\n","        debug_print(f'!! convert_rare_values_to_others for \"{feature}\"')\n","        debug_print(f'value_counts: {len(value_counts)}')\n","        debug_print(f'value_counts[0]: {value_counts[0]}')\n","        debug_print(f'value_counts[{how_many_to_keep}]: {value_counts[how_many_to_keep]}')\n","        debug_print(f'difference is {difference_times} times')\n","\n","    allowed_values = value_counts.index[0: how_many_to_keep]\n","    data[feature] = data[feature].apply(lambda x: x if x in allowed_values else '-- others --')\n","\n","onehot_encoders = None\n","\n","def apply_onehot(data=None, features=None):\n","    global onehot_encoders\n","\n","    if onehot_encoders is None:\n","        onehot_encoders = dict()\n","\n","    for feature in features:\n","        # print(f'\"{feature}\" unique values: {len(data[feature].unique())}')\n","        if len(data[feature].unique()) > 15:\n","            convert_rare_values_to_others(data, feature)\n","        \n","        if onehot_encoders.get(feature) is None:\n","            onehot_encoders[feature] = ce.OneHotEncoder()\n","            onehot_encoders[feature].fit(data[feature])\n","\n","        encoded_feature = onehot_encoders[feature].transform(data[feature])\n","        data[encoded_feature.columns] = encoded_feature\n","        # data.drop(columns=[feature], inplace=True)\n","        pass\n","\n","binary_encoders = None\n","\n","def apply_binary(data=None, features=None, is_test=False):\n","    global binary_encoders\n","\n","    if binary_encoders is None:\n","        binary_encoders = dict()\n","\n","    for feature in features:\n","        # print(f'len(data[feature].unique()) = {len(data[feature].unique())}')\n","        if len(data[feature].unique()) > 127:\n","            convert_rare_values_to_others(data, feature, how_many_to_keep=127)\n","\n","        if binary_encoders.get(feature) is None:\n","            binary_encoders[feature] = ce.BinaryEncoder()\n","            binary_encoders[feature].fit(data[feature])\n","\n","        encoded_feature = binary_encoders[feature].transform(data[feature])\n","        data[encoded_feature.columns] = encoded_feature\n","        # data.drop(columns=[feature], inplace=True)\n","        pass\n","\n","def debug_print(*args, **kwargs):\n","    global DEBUG\n","\n","    if DEBUG:\n","        print(*args, **kwargs)\n","\n","\n","def logger(fn):\n","    def decorated(*args, **kwargs):\n","        debug_print(f'>>> fn. `{fn.__name__}` is running')\n","        ts = time.time()\n","        res = fn(*args, **kwargs)\n","        te = time.time()\n","        delta = round((te-ts) * 1000)\n","        sec_mls = 'mls'\n","        if delta > 1000:\n","            delta = round(delta / 1000, 1)\n","            sec_mls = 's'\n","        debug_print(f'<<< fn. `{fn.__name__}` finished, took {delta} {sec_mls}')\n","        return res\n","    return decorated"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T09:46:22.310113Z","iopub.status.busy":"2022-04-26T09:46:22.309802Z","iopub.status.idle":"2022-04-26T09:46:26.184893Z","shell.execute_reply":"2022-04-26T09:46:26.183771Z","shell.execute_reply.started":"2022-04-26T09:46:22.310074Z"},"trusted":true},"outputs":[],"source":["hotels_test = pd.read_csv(SOURCE_DIR + 'hotels_test.csv.zip', sep=',')\n","hotels_train = pd.read_csv(SOURCE_DIR + 'hotels_train.csv.zip', sep=',')\n","submission = pd.read_csv(SOURCE_DIR + 'submission.csv.zip', sep=',')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T09:46:26.187399Z","iopub.status.busy":"2022-04-26T09:46:26.186749Z","iopub.status.idle":"2022-04-26T09:46:26.254612Z","shell.execute_reply":"2022-04-26T09:46:26.252793Z","shell.execute_reply.started":"2022-04-26T09:46:26.187363Z"},"trusted":true},"outputs":[],"source":["hotels = hotels_train.copy()\n","\n","hotels.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Data cleaning\n","\n","- remove duplicates\n","- remove anomalies\n","- handle missing data in cells (fix them or remove rows)\n","- remove useless features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T10:28:31.460371Z","iopub.status.busy":"2022-04-26T10:28:31.460059Z","iopub.status.idle":"2022-04-26T10:28:31.481555Z","shell.execute_reply":"2022-04-26T10:28:31.480794Z","shell.execute_reply.started":"2022-04-26T10:28:31.460338Z"},"trusted":true},"outputs":[],"source":["@logger\n","def remove_duplicates(data, is_test_data):\n","    # might remove some rows\n","    # we don't want that for the test set\n","    if is_test_data:\n","        return\n","\n","    if INDEX_COLUMN_NAME is None:\n","        return\n","\n","    data.drop(columns=[INDEX_COLUMN_NAME], inplace=True)\n","    m = data.duplicated()\n","    \n","    if m.sum() == 0:\n","        return\n","\n","    data.drop_duplicates(inplace=True)\n","\n","@logger\n","def remove_anomalies(data, is_test_data):\n","    # might remove some rows\n","    # we don't want that for the test set\n","    if is_test_data:\n","        return\n","\n","    describe_hist_box(data, 'additional_number_of_scoring')\n","    m = data['additional_number_of_scoring'] > 1500\n","    debug_print(f'additional_number_of_scoring: {m.sum()}')\n","    data.drop(index=data[m].index, inplace=True)\n","\n","    describe_hist_box(data, 'average_score')\n","    m = data['average_score'] < 6\n","    debug_print(f'average_score: {m.sum()}')\n","    data.drop(index=data[m].index, inplace=True)\n","\n","    describe_hist_box(data, 'review_total_negative_word_counts', log=True)\n","    m = data['review_total_negative_word_counts'] > 60\n","    debug_print(f'review_total_negative_word_counts: {m.sum()}')\n","    data.drop(index=data[m].index, inplace=True)\n","\n","    describe_hist_box(data, 'total_number_of_reviews', log=True)\n","    m = data['total_number_of_reviews'] > 6500\n","    debug_print(f'total_number_of_reviews: {m.sum()}')\n","    data.drop(index=data[m].index, inplace=True)\n","\n","    describe_hist_box(data, 'review_total_positive_word_counts', log=True)\n","    m = data['review_total_positive_word_counts'] > 2e2\n","    debug_print(f'review_total_positive_word_counts: {m.sum()}')\n","    data.drop(index=data[m].index, inplace=True)\n","\n","    describe_hist_box(data, 'total_number_of_reviews_reviewer_has_given', log=True)\n","    m = data['total_number_of_reviews_reviewer_has_given'] > 100\n","    debug_print(f'total_number_of_reviews_reviewer_has_given: {m.sum()}')\n","    data.drop(index=data[m].index, inplace=True)\n","\n","    describe_hist_box(data, 'reviewer_score')\n","    m = data['reviewer_score'] < 5\n","    debug_print(f'reviewer_score: {m.sum()}')\n","    data.drop(index=data[m].index, inplace=True)\n","\n","@logger\n","def handle_missing_data_in_cells(data, is_test_data):\n","    # data are missing in columns `lat` and `lng`\n","    # we will deal that later\n","    pass\n","\n","@logger\n","def remove_useless_features(data, is_test_data):\n","    # columns `hotel_name` and `review_date` do not look important\n","    data.drop(columns=['hotel_name', 'review_date'], inplace=True)\n","\n","@logger\n","def run_cleaning(data=None, is_test_data=False):\n","    data_copy = data.copy()\n","\n","    remove_duplicates(data_copy, is_test_data)\n","    remove_anomalies(data_copy, is_test_data)\n","    handle_missing_data_in_cells(data_copy, is_test_data)\n","    remove_useless_features(data_copy, is_test_data)\n","\n","    rows_before = data.shape[0]\n","    rows_after = data_copy.shape[0]\n","    delta = rows_before - rows_after\n","    percent = round(delta / rows_before * 100.0, 1)\n","    debug_print(f'cleaning removed {delta} rows ({percent}%)')\n","\n","    return data_copy.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Feature creation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T09:46:26.294544Z","iopub.status.busy":"2022-04-26T09:46:26.293632Z","iopub.status.idle":"2022-04-26T09:46:26.330110Z","shell.execute_reply":"2022-04-26T09:46:26.328868Z","shell.execute_reply.started":"2022-04-26T09:46:26.294148Z"},"trusted":true},"outputs":[],"source":["@logger\n","def replace_address_with_hotel_city(data):\n","    def get_city(addr):\n","        city_country = addr.split(' ')[-2:]\n","        if ' '.join(city_country) == 'United Kingdom':\n","            return 'London'\n","        return city_country[0]        \n","\n","    data['hotel_city'] = data['hotel_address'].apply(get_city)\n","    # data.drop(columns=['hotel_address'], inplace=True)\n","    pass\n","\n","@logger\n","def replace_review_with_review_polarity(data):\n","    def calc_polarity(text):\n","        return TextBlob(text).sentiment.polarity\n","\n","    data['negative_review_polarity'] = data['negative_review'].apply(calc_polarity)\n","    data['positive_review_polarity'] = data['positive_review'].apply(calc_polarity)\n","    data.drop(columns=['negative_review', 'positive_review'], inplace=True)\n","\n","@logger\n","def convert_days_since_review(data):\n","    data['days_since_review_number'] = data['days_since_review'].apply(lambda x: int(x.split(' ')[0]))\n","    data.drop(columns=['days_since_review'], inplace=True)\n","\n","@logger\n","def convert_lat_lng_to_distance(data):\n","    m = data['lat'].notna()\n","\n","    def get_city_lat_lng(city):\n","        if city == 'London':\n","            return { 'lat': 51.5072, 'lng': 0.1276 }\n","        if city == 'Paris':\n","            return { 'lat': 48.8566, 'lng': 2.3522 }\n","        if city == 'Barcelona':\n","            return { 'lat': 41.3874, 'lng': 2.1686 }\n","        if city == 'Amsterdam':\n","            return { 'lat': 52.3676, 'lng': 4.9041 }\n","        if city == 'Vienna':\n","            return { 'lat': 48.2082, 'lng': 16.3738 }\n","        if city == 'Milan':\n","            return { 'lat': 45.4642, 'lng': 9.1900 }\n","\n","    data.loc[m, 'city_center_lat'] = data[m]['hotel_city'].apply(lambda x: get_city_lat_lng(x)['lat'])\n","    data.loc[m, 'city_center_lng'] = data[m]['hotel_city'].apply(lambda x: get_city_lat_lng(x)['lng'])\n","\n","    def get_distance(cols):\n","        coord_1 = (cols['city_center_lat'], cols['city_center_lng'])\n","        coord_2 = (cols['lat'], cols['lng'])\n","        return distance.distance(coord_1, coord_2).km\n","\n","    data.loc[m, 'distance_from_center_km'] = data[m].apply(get_distance, axis=1)\n","    data.drop(columns=['lat', 'lng', 'city_center_lat', 'city_center_lng'], inplace=True)\n","\n","@logger\n","def fill_in_missing_distance(data):\n","    city_median_distance = data.groupby('hotel_city').agg('distance_from_center_km').median()\n","    m = data['distance_from_center_km'].isna()\n","    data.loc[m, 'distance_from_center_km'] = data[m]['hotel_city'].apply(lambda x: city_median_distance[x])\n","\n","@logger\n","def convert_tags(data):\n","    def analize_tags(tag_list_json_str):\n","        tag_list = json.loads(tag_list_json_str.replace('\\'', '\"'))\n","        tags_count = len(tag_list)\n","        all_tags_joined = ', '.join(tag_list)\n","        all_tags_words = [w for w in all_tags_joined.split(' ') if w.strip() != '']\n","        tag_words_count = len(all_tags_words)\n","        return pd.Series([tags_count, tag_words_count, all_tags_joined])\n","\n","    data[['tags_count', 'tag_words_count', 'all_tags_joined']] = data['tags'].apply(analize_tags)\n","\n","@logger\n","def replace_all_tags_with_tags_polarity(data):\n","    def calc_polarity(text):\n","        return TextBlob(text).sentiment.polarity\n","\n","    data['tags_polarity'] = data['all_tags_joined'].apply(calc_polarity)\n","    # data.drop(columns=['all_tags_joined'], inplace=True)\n","    pass\n","\n","@logger\n","def create_features(data=None):\n","    data_copy = data.copy()\n","    replace_address_with_hotel_city(data_copy)\n","    replace_review_with_review_polarity(data_copy)\n","    convert_days_since_review(data_copy)\n","    convert_tags(data_copy)\n","    replace_all_tags_with_tags_polarity(data_copy)\n","    convert_lat_lng_to_distance(data_copy)\n","    fill_in_missing_distance(data_copy)\n","    apply_onehot(data_copy, ['hotel_city'])\n","    apply_binary(data_copy, ['reviewer_nationality'])\n","\n","    return data_copy"]},{"cell_type":"markdown","metadata":{},"source":["# Feature transformation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T09:46:26.333138Z","iopub.status.busy":"2022-04-26T09:46:26.332482Z","iopub.status.idle":"2022-04-26T09:46:26.355956Z","shell.execute_reply":"2022-04-26T09:46:26.353569Z","shell.execute_reply.started":"2022-04-26T09:46:26.333078Z"},"trusted":true},"outputs":[],"source":["stnd_scaler = None\n","\n","@logger\n","def standardize_features(data, features):\n","    global stnd_scaler\n","\n","    if stnd_scaler is None:\n","        stnd_scaler = preprocessing.StandardScaler().fit(data[features])\n","        # stnd_scaler\n","\n","    ndarr = stnd_scaler.transform(data[features])\n","    stnd_df = pd.DataFrame(ndarr, columns=[features])\n","    data.loc[:, features] = stnd_df[features]\n","\n","norm_scaler = None\n","\n","@logger\n","def normalize_features(data, features):\n","    global norm_scaler\n","\n","    if norm_scaler is None:\n","        norm_scaler = preprocessing.MinMaxScaler().fit(data[features])\n","        # norm_scaler.fit(data)\n","\n","    ndarr = norm_scaler.transform(data[features])\n","    norm_df = pd.DataFrame(ndarr, columns=[features])\n","    data.loc[:, features] = norm_df[features]\n","\n","@logger\n","def transform_features(data=None):\n","    data_copy = data.copy()\n","\n","    standardize_features(data_copy, ['tag_words_count'])\n","    normalize_features(data_copy, [\n","        'additional_number_of_scoring',\n","        'review_total_negative_word_counts',\n","        'total_number_of_reviews',\n","        'review_total_positive_word_counts',\n","        'total_number_of_reviews_reviewer_has_given',\n","        'days_since_review_number',\n","        'distance_from_center_km'])\n","\n","    return data_copy\n"]},{"cell_type":"markdown","metadata":{},"source":["# Feature selection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T10:35:19.073599Z","iopub.status.busy":"2022-04-26T10:35:19.072970Z","iopub.status.idle":"2022-04-26T10:35:19.087632Z","shell.execute_reply":"2022-04-26T10:35:19.086913Z","shell.execute_reply.started":"2022-04-26T10:35:19.073567Z"},"trusted":true},"outputs":[],"source":["def visualize_num_cols_importance(X, y, ax):\n","    # непрерывные признаки\n","    num_cols = [\n","        'additional_number_of_scoring',\n","        'average_score',\n","        'review_total_negative_word_counts',\n","        'total_number_of_reviews',\n","        'review_total_positive_word_counts',\n","        'total_number_of_reviews_reviewer_has_given',\n","        'negative_review_polarity',\n","        'positive_review_polarity',\n","        'tag_words_count',\n","        'days_since_review_number',\n","        'tags_polarity',\n","        'distance_from_center_km']\n","\n","    f_classif_results = f_classif(X[num_cols], y)\n","\n","    data = pd.DataFrame(data=f_classif_results[0], index=num_cols, columns=['value'])\n","    data.sort_values(by=['value'], inplace=True, ascending=False)\n","\n","    sns.barplot(ax=ax, data=data, x='value', y=data.index)\n","    ax.set_title('Importance of numeric features')\n","\n","def visualize_cat_cols_importance(X, y, ax):\n","    # категориальные признаки\n","    cat_cols = [\n","        'tags_count',\n","        'hotel_city_1',\n","        'hotel_city_2',\n","        'hotel_city_3',\n","        'hotel_city_4',\n","        'hotel_city_5',\n","        'hotel_city_6',\n","        'reviewer_nationality_0',\n","        'reviewer_nationality_1',\n","        'reviewer_nationality_2',\n","        'reviewer_nationality_3',\n","        'reviewer_nationality_4',\n","        'reviewer_nationality_5',\n","        'reviewer_nationality_6',\n","        'reviewer_nationality_7']\n","\n","    chi2_results = chi2(X[cat_cols], y.astype('int'))\n","\n","    data = pd.DataFrame(data=chi2_results[0], index=cat_cols, columns=['value'])\n","    data.sort_values(by=['value'], ascending=False, inplace=True)\n","\n","    sns.barplot(ax=ax, data=data, x='value', y=data.index)\n","    ax.set_title('Importance of categorical features')\n","\n","def select_features(data=None):\n","    data_copy = data.copy()\n","\n","    X = data_copy.select_dtypes(include=[np.number])\n","    \n","    if TARGET_COLUMN_NAME in X.columns:\n","        X.drop(columns=[TARGET_COLUMN_NAME], inplace=True)\n","\n","        y = data_copy[TARGET_COLUMN_NAME]\n","\n","        global DEBUG\n","\n","        if DEBUG:\n","            fig, ax = figax(figsize=(15, 15), rowcol=(2, 1))\n","\n","            visualize_num_cols_importance(X, y, ax[0])\n","            visualize_cat_cols_importance(X, y, ax[1])\n","\n","    data_copy.drop(columns=[\n","        'days_since_review_number',\n","        # 'reviewer_nationality_7',\n","        # 'reviewer_nationality_0',\n","    ], inplace=True)\n","\n","    return data_copy\n"]},{"cell_type":"markdown","metadata":{},"source":["# Model training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T10:53:13.222435Z","iopub.status.busy":"2022-04-26T10:53:13.222140Z","iopub.status.idle":"2022-04-26T10:53:13.235336Z","shell.execute_reply":"2022-04-26T10:53:13.234647Z","shell.execute_reply.started":"2022-04-26T10:53:13.222405Z"},"trusted":true},"outputs":[],"source":["@logger\n","def split_to_train_test(data):\n","    X = data.select_dtypes(include=[np.number])\n","    X.drop(columns=[TARGET_COLUMN_NAME], inplace=True)\n","    y = data[TARGET_COLUMN_NAME]\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    return X_train, X_test, y_train, y_test\n","\n","regr_model = None\n","\n","@logger\n","def train_model(X_train, y_train):\n","    global regr_model\n","\n","    regr_model = RandomForestRegressor(n_estimators=50)\n","    regr_model.fit(X_train, y_train)\n","\n","@logger\n","def estimate_model(X_test, y_test):\n","    global regr_model\n","\n","    y_pred = regr_model.predict(X_test.select_dtypes(include=[np.number]))\n","    print('MAPE:', metrics.mean_absolute_percentage_error(y_test, y_pred))\n","\n","@logger\n","def train_and_estimate(data):\n","    X_train, X_test, y_train, y_test = split_to_train_test(data)\n","\n","    train_model(X_train, y_train)\n","\n","    estimate_model(X_test, y_test)\n","\n","@logger\n","def prepare_data(data=None, is_test_data=False):\n","    data_copy = data.copy()\n","\n","    data_copy = run_cleaning(data_copy, is_test_data)\n","    data_copy = create_features(data_copy)\n","    data_copy = transform_features(data_copy)\n","    data_copy = select_features(data_copy)\n","    data_copy = data_copy.select_dtypes(include=[np.number])\n","\n","    return data_copy"]},{"cell_type":"markdown","metadata":{},"source":["# Running it all out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T09:46:26.411088Z","iopub.status.busy":"2022-04-26T09:46:26.410802Z","iopub.status.idle":"2022-04-26T09:59:40.135396Z","shell.execute_reply":"2022-04-26T09:59:40.134289Z","shell.execute_reply.started":"2022-04-26T09:46:26.411058Z"},"trusted":true},"outputs":[],"source":["train_data = prepare_data(hotels)\n","train_and_estimate(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["# Predict and save submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T10:53:22.472786Z","iopub.status.busy":"2022-04-26T10:53:22.472083Z"},"trusted":true},"outputs":[],"source":["test_data = prepare_data(hotels_test, is_test_data=True)\n","test_pred = regr_model.predict(test_data)\n","print(f'Prediction for te_data:\\n{test_pred}\\nShape = {test_pred.shape}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-26T10:51:31.248392Z","iopub.status.busy":"2022-04-26T10:51:31.248099Z","iopub.status.idle":"2022-04-26T10:51:31.281056Z","shell.execute_reply":"2022-04-26T10:51:31.279850Z","shell.execute_reply.started":"2022-04-26T10:51:31.248360Z"},"trusted":true},"outputs":[],"source":["submission[TARGET_COLUMN_NAME] = test_pred\n","submission.to_csv('hotels_prediction.csv', index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
