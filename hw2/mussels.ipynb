{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/evpozdniakov/ds_projects/blob/master/hw2/mussels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявляем исходные данные: размеры раковин мидий выращенных в разных городах-производителях. (Их мы получили вместе с заданием. Также известно, что данные имеют *нормальное распределение*.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "petersburg = [0.0974, 0.1352, 0.0817, 0.1016, 0.0968, 0.1064, 0.105]\n",
    "magadan = [0.1033, 0.0915, 0.0781, 0.0685, 0.0677, 0.0697, 0.0764, 0.0689]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно приступать к работе. Выполним первый шаг.\n",
    "\n",
    "#### 1. Объединить 2 массива в DataFrame\n",
    "\n",
    "Наши массивы имеют разный размер. Мы можем воспользоваться стандартным методом создания датафрейма из Series:\n",
    "\n",
    "```python\n",
    "pd.DataFrame({'a': pd.Series(a), 'b': pd.Series(b)})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'St.Petersburg': pd.Series(petersburg),\n",
    "    'Magadan': pd.Series(magadan),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>St.Petersburg</th>\n",
       "      <th>Magadan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.0915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.0781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.0685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.0677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   St.Petersburg  Magadan\n",
       "0         0.0974   0.1033\n",
       "1         0.1352   0.0915\n",
       "2         0.0817   0.0781\n",
       "3         0.1016   0.0685\n",
       "4         0.0968   0.0677\n",
       "5         0.1064   0.0697\n",
       "6         0.1050   0.0764\n",
       "7            NaN   0.0689"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что недостающие данные были заменены на **NaN**. Прежде чем продолжать работу, нам нужно исправить эту ситуацию.\n",
    "\n",
    "Недостающие данные мы можем заполнить или *средним* значением данного признака, или *медианным*. В нашем случае выбор не будет иметь решающего значения, но на всякий случай сделаем два варианта и проверим как они себя поведут, и повлияет ли этот выбор на конечный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['St.Petersburg'].isna()\n",
    "\n",
    "df_clean_avg = df.copy()\n",
    "df_clean_avg.loc[mask, 'St.Petersburg'] = df['St.Petersburg'].mean()\n",
    "\n",
    "df_clean_med = df.copy()\n",
    "df_clean_med.loc[mask, 'St.Petersburg'] = df['St.Petersburg'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем что получилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   St.Petersburg  Magadan\n",
      "0       0.097400   0.1033\n",
      "1       0.135200   0.0915\n",
      "2       0.081700   0.0781\n",
      "3       0.101600   0.0685\n",
      "4       0.096800   0.0677\n",
      "5       0.106400   0.0697\n",
      "6       0.105000   0.0764\n",
      "7       0.103443   0.0689\n",
      "\n",
      "   St.Petersburg  Magadan\n",
      "0         0.0974   0.1033\n",
      "1         0.1352   0.0915\n",
      "2         0.0817   0.0781\n",
      "3         0.1016   0.0685\n",
      "4         0.0968   0.0677\n",
      "5         0.1064   0.0697\n",
      "6         0.1050   0.0764\n",
      "7         0.1016   0.0689\n"
     ]
    }
   ],
   "source": [
    "print(df_clean_avg, df_clean_med, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее в нашем исследовании мы будем использовать оба датафрейма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Проверить данные на нормальность\n",
    "\n",
    "Наша нулевая гипотеза будет утверждать, что данные распределены нормально.\n",
    "Наша альтернативная гипотеза будет утверждать обратное.\n",
    "\n",
    "Уровень значимости установим стандартный - 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = 'Данные распределены нормально'\n",
    "Ha = 'Данные не распределены нормально'\n",
    "\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем оба датафрейма. Для проверки будем использовать тест Шапиро-Уилка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка нормального распределения для датафрейма \"df_clean_avg\"\n",
      "P-value = 0.100\n",
      "Данные распределены нормально\n",
      "\n",
      "Проверка нормального распределения для датафрейма \"df_clean_med\"\n",
      "P-value = 0.101\n",
      "Данные распределены нормально\n"
     ]
    }
   ],
   "source": [
    "def test_normal_distribution(df, df_name):\n",
    "    print(f'Проверка нормального распределения для датафрейма \"{df_name}\"')\n",
    "\n",
    "    _, p = shapiro(df)\n",
    "\n",
    "    print(f'P-value = {p:.3f}')\n",
    "\n",
    "    if p > alpha:\n",
    "        print(H0)\n",
    "    else:\n",
    "        print(Ha)\n",
    "\n",
    "\n",
    "test_normal_distribution(df_clean_avg, 'df_clean_avg')\n",
    "print('')\n",
    "test_normal_distribution(df_clean_med, 'df_clean_med')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты теста Шапиро-Уилка показывают, что нам не удалось опровергнуть нулевую гипотезу. Следовательно мы можем с большой долей вероятности полагать, что наши данные распределены нормально.\n",
    "\n",
    "Отметим также, что тест вернул одинаковые результаты для обоих наших датафреймов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Выбрать тест на корреляцию и обосновать свой выбор\n",
    "\n",
    "Какие существуют корреляционные тесты? В нашем арсенале их три:\n",
    "\n",
    "- Корреляция Пирсона\n",
    "- Корреляция Спирмена\n",
    "- χ²-тест\n",
    "\n",
    "Для выбора теста попробуем действовать метдом исключения.\n",
    "\n",
    "**χ²-тест** нам не подходит, поскольку он применяется для категориальных переменных, а наши переменные являются числовыми и непрерывными.\n",
    "\n",
    "**Корреляция Спирмена** нам не подходит, потому что она используется для поиска зависимостей между негаусовскими величинами, а наши данные, как мы выяснили, скорее всего имеют нормальное распределение.\n",
    "\n",
    "Остается **параметрический тест на корреляцию Пирсона**. И действительно, он предназначен для поиска корреляции между непрерывными числовыми переменными, имеющими нормальное распределение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Проверить данные на наличие корреляции\n",
    "\n",
    "Наша нулевая гипотеза будет предполагать, что корреляция в данных отсутствует. Альтернативная гипотеза будет предполагать, что корреляция в данных присутствует. \n",
    "\n",
    "Уровень значимости установим стандартный - 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = 'Корреляция в размерах мидий отстуствует'\n",
    "Ha = 'Корреляция в размерах мидий присутствует'\n",
    "\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем оба датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка корреляции по методу Пирсона для датафрейма \"df_clean_avg\"\n",
      "P-value = 0.559\n",
      "Корреляция в размерах мидий отстуствует\n",
      "\n",
      "Проверка корреляции по методу Пирсона для датафрейма \"df_clean_med\"\n",
      "P-value = 0.539\n",
      "Корреляция в размерах мидий отстуствует\n"
     ]
    }
   ],
   "source": [
    "def test_pearson_corr(df, df_name):\n",
    "    print(f'Проверка корреляции по методу Пирсона для датафрейма \"{df_name}\"')\n",
    "\n",
    "    _, p = pearsonr(df['St.Petersburg'], df['Magadan'])\n",
    "\n",
    "    print(f'P-value = {p:.3f}')\n",
    "\n",
    "    if p > alpha:\n",
    "        print(H0)\n",
    "    else:\n",
    "        print(Ha)\n",
    "    \n",
    "test_pearson_corr(df_clean_avg, 'df_clean_avg')\n",
    "print('')\n",
    "test_pearson_corr(df_clean_med, 'df_clean_med')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Сделать вывод по гипотезе\n",
    "\n",
    "Тест Пирсона вернул значение **P-value** больше **α**. Следовательно, мы не можем опровергнуть нулевую гипотезу. Следовательно, с высокой долей вероятности мы можем утверждать, что размеры мидий из Санкт-Петербурга не оказывают влияния на размеры мидий из Магадана.\n",
    "\n",
    "Нужно отметить, что тест Пирсона вернул одинаковые результаты для обоих наших датафреймов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Выбрать тест на сравнение и обосновать свой выбор.\n",
    "\n",
    "Разобраться с лекционным материалом нелегко, многие вещи описаны довольно абстрактно. Ну что же, воспользуемся тем, что есть.\n",
    "\n",
    "Поскольку наши данные имеют нормальное распределение, то мы будем выбирать тест на сравнение из числа **параметрических** статистических методов.\n",
    "\n",
    "![Выбор статистических методов](images/dst-eda-4-7.png)\n",
    "\n",
    "Сравнительные тесты ищут различия в средних параметрах по группам. Они помогают ответить на вопрос, влияет ли некая категория на среднее значение некоего числового признака. Например, влияет ли гендер на среднюю ЗП.\n",
    "\n",
    "Причем категорий для сравнения может быть не две а больше, а сравниваемых групп может быть как несколько, так и всего одна.\n",
    "\n",
    "Группы могут быть происходить из одной совокупности или из разных, где совокупность есть набор данных со схожими параметрами. Например если из учеников одного класса сформировать две группы, то эти группы будут происходить из одной совокупности.\n",
    "\n",
    "Воспользуемся таблицей из лекционного материала.\n",
    "\n",
    "![Параметрические тесты на сравнение выборок](images/dst-eda-4-9.png)\n",
    "\n",
    "Чтобы выбрать правильный тест нам нужно понять сколько в нашем случае имеется независимых переменных, сколько зависимых, и каков характер сравниваемых групп.\n",
    "\n",
    "У нас имеется одна независимая переменная — город производства. Зависимая переменная у нас тоже одна — средний размер мидий. Наши группы происходят из разных совокупностей поскольку мидии выращены в разных местах.\n",
    "\n",
    "Согласно таблице мы можем воспользоваться использовать либо **независимый t-тест**, либо тест **ANOVA**.\n",
    "\n",
    "Воспользуемся еще одной таблице из лекций.\n",
    "\n",
    "![Подбор теста на сравнение выборок](images/dst-eda-4-10.png)\n",
    "\n",
    "Согласно схеме выше, тест **ANOVA** применяют тогда, когда количество сравниваемых групп больше двух. Если же групп всего две, то применяют либо **T-тест**, либо **Z-тест**, что зависит от числа элементов в группах.\n",
    "\n",
    "Поскольку в наших группах элементов меньше тридцати, то нам нужно использовать **T-тест**.\n",
    "\n",
    "Получается, что согласно одной таблице нам нужно использовать **независимый t-тест**, а согласно другой — **T-тест**. Нет ли здесь противоречия?\n",
    "\n",
    "# 🤔\n",
    "\n",
    "Вероятно **T-тест**, упоминаемый в схеме выше, делает отсылку к *семейству T-тестов*. Похоже на то, ведь на странице модуля ScyPi, [посвященной статистическим тестам](https://docs.scipy.org/doc/scipy/reference/stats.html#module-scipy.stats), упоминается их четыре разновидности.\n",
    "\n",
    "![T-тесты модуля ScyPi](images/Screenshot%202022-03-13%20at%2009.21.12.png)\n",
    "\n",
    "Осталось выбрать один из них. Нам должен подойти **ttest_ind**, согласно описанию он делает как раз то, что нам нужно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Провести тест на сравнение\n",
    "\n",
    "Декларируем наши гипотезы и выбираем уровень значимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = 'Нет значимой разницы в средних значениях размеров мидий.'\n",
    "Ha = 'Есть значимая разница в средних значениях размеров мидий.'\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проводим тест для обоих наших датафреймов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Независимый T-тест для датафрейма \"df_clean_avg\"\n",
      "P-value = 0.003\n",
      "Есть значимая разница в средних значениях размеров мидий.\n",
      "\n",
      "Независимый T-тест для датафрейма \"df_clean_med\"\n",
      "P-value = 0.003\n",
      "Есть значимая разница в средних значениях размеров мидий.\n"
     ]
    }
   ],
   "source": [
    "def run_ttest_ind(df, df_name):\n",
    "    print(f'Независимый T-тест для датафрейма \"{df_name}\"')\n",
    "\n",
    "    _, p = ttest_ind(df['St.Petersburg'], df['Magadan'])\n",
    "\n",
    "    print(f'P-value = {p:.3f}')\n",
    "\n",
    "    if p > alpha:\n",
    "        print(H0)\n",
    "    else:\n",
    "        print(Ha)\n",
    "\n",
    "run_ttest_ind(df_clean_avg, 'df_clean_avg')\n",
    "print('')\n",
    "run_ttest_ind(df_clean_med, 'df_clean_med')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Сделать вывод по гипотезе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наш тест показал, что средний размер мидий, произведенных в Санкт-Петербурге и Магадане, существенно отличается. Но нужно отметить, что мы можем утверждать это лишь с вероятностью 95%, поскольку выбранный нами уровень значимости дает 5%-ный риск ошибки.\n",
    "\n",
    "Отметим также, что тест вернул одинаковые результаты для обоих наших датафреймов.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0821dd16dfa9b2597403627502e313c795e583c1c5167727d89e40ba1b00626"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
