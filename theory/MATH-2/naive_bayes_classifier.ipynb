{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data = pd.read_csv('./SMSSpamCollection.zip', sep='\t', names=['target', 'text'], header=None)\n",
    "\n",
    "sms_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleanup(data):\n",
    "    data['text'] = data['text'].str.replace('\\W+', ' ', regex=True)\n",
    "    data['text'] = data['text'].str.replace('\\s+', ' ', regex=True)\n",
    "    data['text'] = data['text'].str.strip()\n",
    "    data['text'] = data['text'].str.lower()\n",
    "\n",
    "text_cleanup(sms_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set(word for sms in sms_data['text'].values for word in sms.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8753"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_data.loc[:, 'target'] = sms_data['target'] == 'spam'\n",
    "sms_data.loc[:, 'target'] = np.int8(sms_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "X = sms_data['text']\n",
    "y = sms_data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ev/miniconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "word_stats = sms_data.copy()\n",
    "word_stats.rename(columns={'text': 'orig_text'}, inplace=True)\n",
    "\n",
    "word_stats\n",
    "\n",
    "for word in vocabulary:\n",
    "    word_stats.loc[:, word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, row) in zip(word_stats.index, word_stats.values):\n",
    "    orig = row[1]\n",
    "    for word in orig.split():\n",
    "        word_stats.loc[idx, word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = list(vocabulary)\n",
    "m_spam = word_stats['target'] == 1\n",
    "m_nospam = word_stats['target'] == 0\n",
    "word_is_spam = word_stats[m_spam][words_list].sum(axis=0)\n",
    "word_is_nospam = word_stats[m_nospam][words_list].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_usage = word_stats[words_list].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_count = m_spam.sum()\n",
    "ham_count = m_nospam.sum()\n",
    "\n",
    "words_probabilities = pd.DataFrame(\n",
    "    data=[\n",
    "        [word_is_spam[word] / spam_count for word in words_list],\n",
    "        [word_is_nospam[word] / ham_count for word in words_list],\n",
    "    ],\n",
    "    columns=words_list,\n",
    "    index=['word_is_spam_p', 'word_is_ham_p']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conditions</th>\n",
       "      <th>ended</th>\n",
       "      <th>jan</th>\n",
       "      <th>quality</th>\n",
       "      <th>someplace</th>\n",
       "      <th>25p</th>\n",
       "      <th>idiot</th>\n",
       "      <th>lazy</th>\n",
       "      <th>fireplace</th>\n",
       "      <th>82050</th>\n",
       "      <th>...</th>\n",
       "      <th>peripherals</th>\n",
       "      <th>costume</th>\n",
       "      <th>tamilnadu</th>\n",
       "      <th>senrd</th>\n",
       "      <th>icon</th>\n",
       "      <th>out</th>\n",
       "      <th>buz</th>\n",
       "      <th>mutai</th>\n",
       "      <th>winds</th>\n",
       "      <th>massive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_is_spam_p</th>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01071</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_is_ham_p</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.044352</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 8753 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                conditions     ended       jan   quality  someplace      25p  \\\n",
       "word_is_spam_p    0.005355  0.000000  0.000000  0.002677   0.000000  0.01071   \n",
       "word_is_ham_p     0.000207  0.001244  0.000622  0.001036   0.000207  0.00000   \n",
       "\n",
       "                   idiot      lazy  fireplace     82050  ...  peripherals  \\\n",
       "word_is_spam_p  0.001339  0.000000   0.000000  0.002677  ...     0.000000   \n",
       "word_is_ham_p   0.000622  0.001865   0.000207  0.000000  ...     0.000207   \n",
       "\n",
       "                 costume  tamilnadu     senrd      icon       out       buz  \\\n",
       "word_is_spam_p  0.000000   0.000000  0.000000  0.000000  0.080321  0.000000   \n",
       "word_is_ham_p   0.000207   0.000207  0.000207  0.000207  0.044352  0.000207   \n",
       "\n",
       "                   mutai     winds   massive  \n",
       "word_is_spam_p  0.000000  0.000000  0.000000  \n",
       "word_is_ham_p   0.000207  0.000207  0.000415  \n",
       "\n",
       "[2 rows x 8753 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_is_spam_p = spam_count / (spam_count + ham_count)\n",
    "sms_is_ham_p = ham_count / (spam_count + ham_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_list(num_list):\n",
    "    res = 1\n",
    "    for n in num_list:\n",
    "        res *= n\n",
    "\n",
    "    return res\n",
    "\n",
    "def detect_spam(sms, show=True):\n",
    "    sms_df = pd.DataFrame({\n",
    "        'text': [sms],\n",
    "    })\n",
    "\n",
    "    text_cleanup(sms_df)\n",
    "\n",
    "    sms_cleaned = sms_df['text'].values[0]\n",
    "\n",
    "    sms_words = sms_cleaned.split()\n",
    "\n",
    "    is_spam_p = sms_is_spam_p * multiply_list([words_probabilities.loc['word_is_spam_p', word] for word in sms_words])\n",
    "    is_ham_p = sms_is_ham_p * multiply_list([words_probabilities.loc['word_is_ham_p', word] for word in sms_words])\n",
    "\n",
    "    is_spam_res = is_spam_p >= is_ham_p\n",
    "\n",
    "    if show:\n",
    "        print(f'is_ham_p: {is_ham_p}')\n",
    "        print(f'is_spam_p: {is_spam_p}')\n",
    "        print('SPAM' if is_spam_res else 'ham')\n",
    "    else:\n",
    "        return 1 if is_spam_res else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    return X.apply(lambda sms: detect_spam(sms, False))\n",
    "\n",
    "y_test_pred = predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       966\n",
      "           1       0.97      1.00      0.98       149\n",
      "\n",
      "    accuracy                           1.00      1115\n",
      "   macro avg       0.98      1.00      0.99      1115\n",
      "weighted avg       1.00      1.00      1.00      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# print(f'Accuracy: {metrics.accuracy_score(y_test, y_test_pred)}')\n",
    "# print(f'Precision: {metrics.precision_score(y_test, y_test_pred)}')\n",
    "# print(f'Recall: {metrics.recall_score(y_test, y_test_pred)}')\n",
    "# print(f'F₁ score: {metrics.f1_score(y_test, y_test_pred)}')\n",
    "print(metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "# confusion_matrix = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "# sns.heatmap(confusion_matrix, annot=True, fmt='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
